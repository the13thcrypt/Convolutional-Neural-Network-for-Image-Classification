{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOruGhtarI2o"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "0Ifb3HTCri_k"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "PjA5Sna7roNb"
      },
      "outputs": [],
      "source": [
        "train_data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "#train loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "vOIP8t-csHiI",
        "outputId": "98cf484b-6467-43da-c2ee-943cfeb1b32b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[-0.5373, -0.6627, -0.6078,  ...,  0.2392,  0.1922,  0.1608],\n",
              "         [-0.8745, -1.0000, -0.8588,  ..., -0.0353, -0.0667, -0.0431],\n",
              "         [-0.8039, -0.8745, -0.6157,  ..., -0.0745, -0.0588, -0.1451],\n",
              "         ...,\n",
              "         [ 0.6314,  0.5765,  0.5529,  ...,  0.2549, -0.5608, -0.5843],\n",
              "         [ 0.4118,  0.3569,  0.4588,  ...,  0.4431, -0.2392, -0.3490],\n",
              "         [ 0.3882,  0.3176,  0.4039,  ...,  0.6941,  0.1843, -0.0353]],\n",
              "\n",
              "        [[-0.5137, -0.6392, -0.6235,  ...,  0.0353, -0.0196, -0.0275],\n",
              "         [-0.8431, -1.0000, -0.9373,  ..., -0.3098, -0.3490, -0.3176],\n",
              "         [-0.8118, -0.9451, -0.7882,  ..., -0.3412, -0.3412, -0.4275],\n",
              "         ...,\n",
              "         [ 0.3333,  0.2000,  0.2627,  ...,  0.0431, -0.7569, -0.7333],\n",
              "         [ 0.0902, -0.0353,  0.1294,  ...,  0.1608, -0.5137, -0.5843],\n",
              "         [ 0.1294,  0.0118,  0.1137,  ...,  0.4431, -0.0745, -0.2784]],\n",
              "\n",
              "        [[-0.5059, -0.6471, -0.6627,  ..., -0.1529, -0.2000, -0.1922],\n",
              "         [-0.8431, -1.0000, -1.0000,  ..., -0.5686, -0.6078, -0.5529],\n",
              "         [-0.8353, -1.0000, -0.9373,  ..., -0.6078, -0.6078, -0.6706],\n",
              "         ...,\n",
              "         [-0.2471, -0.7333, -0.7961,  ..., -0.4510, -0.9451, -0.8431],\n",
              "         [-0.2471, -0.6706, -0.7647,  ..., -0.2627, -0.7333, -0.7333],\n",
              "         [-0.0902, -0.2627, -0.3176,  ...,  0.0980, -0.3412, -0.4353]]])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'frog'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "image, label = train_data[0]\n",
        "display(image)\n",
        "display(class_names[label])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsXftRJxslFC",
        "outputId": "9f5a8f78-2ab6-45f5-b7a3-f666563d2869"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[-0.5373, -0.6627, -0.6078,  ...,  0.2392,  0.1922,  0.1608],\n",
              "         [-0.8745, -1.0000, -0.8588,  ..., -0.0353, -0.0667, -0.0431],\n",
              "         [-0.8039, -0.8745, -0.6157,  ..., -0.0745, -0.0588, -0.1451],\n",
              "         ...,\n",
              "         [ 0.6314,  0.5765,  0.5529,  ...,  0.2549, -0.5608, -0.5843],\n",
              "         [ 0.4118,  0.3569,  0.4588,  ...,  0.4431, -0.2392, -0.3490],\n",
              "         [ 0.3882,  0.3176,  0.4039,  ...,  0.6941,  0.1843, -0.0353]],\n",
              "\n",
              "        [[-0.5137, -0.6392, -0.6235,  ...,  0.0353, -0.0196, -0.0275],\n",
              "         [-0.8431, -1.0000, -0.9373,  ..., -0.3098, -0.3490, -0.3176],\n",
              "         [-0.8118, -0.9451, -0.7882,  ..., -0.3412, -0.3412, -0.4275],\n",
              "         ...,\n",
              "         [ 0.3333,  0.2000,  0.2627,  ...,  0.0431, -0.7569, -0.7333],\n",
              "         [ 0.0902, -0.0353,  0.1294,  ...,  0.1608, -0.5137, -0.5843],\n",
              "         [ 0.1294,  0.0118,  0.1137,  ...,  0.4431, -0.0745, -0.2784]],\n",
              "\n",
              "        [[-0.5059, -0.6471, -0.6627,  ..., -0.1529, -0.2000, -0.1922],\n",
              "         [-0.8431, -1.0000, -1.0000,  ..., -0.5686, -0.6078, -0.5529],\n",
              "         [-0.8353, -1.0000, -0.9373,  ..., -0.6078, -0.6078, -0.6706],\n",
              "         ...,\n",
              "         [-0.2471, -0.7333, -0.7961,  ..., -0.4510, -0.9451, -0.8431],\n",
              "         [-0.2471, -0.6706, -0.7647,  ..., -0.2627, -0.7333, -0.7333],\n",
              "         [-0.0902, -0.2627, -0.3176,  ...,  0.0980, -0.3412, -0.4353]]])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJkQBSCRsxhr",
        "outputId": "68014579-fc2f-445e-9816-6cc28c76e21c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 32, 32])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "9RkM4y3Ns1ds"
      },
      "outputs": [],
      "source": [
        "class_names =['plane','car','bird','cat','deer','dog','frog','horse','ship','helicopter']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "fXz3pKOAtLWe"
      },
      "outputs": [],
      "source": [
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.convl = nn.Conv2d(3,12,5) #(12,28,28)\n",
        "    self.pool = nn.MaxPool2d(2,2) #(12,14,14)\n",
        "    self.conv2 = nn.Conv2d(12,24,5) #(24,10,10) -> after pooling (24, 5, 5)\n",
        "    self.fc1 = nn.Linear(24*5*5,120)\n",
        "    self.fc2 = nn.Linear(120,84)\n",
        "    self.fc3 = nn.Linear(84,10)\n",
        "  def forward(self,x):\n",
        "    x = self.pool(F.relu(self.convl(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = torch.flatten(x,1) # flatten all dimensions except batch\n",
        "    x =F.relu(self.fc1(x))\n",
        "    x =F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Q6LhmFkCvmD_"
      },
      "outputs": [],
      "source": [
        "net = NeuralNet()\n",
        "loss_function =nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(),lr=0.001,momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yc19C89_vyQX",
        "outputId": "9c34ec3b-eb7f-44cc-c5e7-4d8756095bab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training epoch 0...\n",
            "Loss: 2.300241\n",
            "Training epoch 1...\n",
            "Loss: 2.300240\n",
            "Training epoch 2...\n",
            "Loss: 2.300240\n",
            "Training epoch 3...\n",
            "Loss: 2.300234\n",
            "Training epoch 4...\n",
            "Loss: 2.300240\n",
            "Training epoch 5...\n",
            "Loss: 2.300239\n",
            "Training epoch 6...\n",
            "Loss: 2.300236\n",
            "Training epoch 7...\n",
            "Loss: 2.300244\n",
            "Training epoch 8...\n",
            "Loss: 2.300239\n",
            "Training epoch 9...\n",
            "Loss: 2.300241\n",
            "Training epoch 10...\n",
            "Loss: 2.300239\n",
            "Training epoch 11...\n",
            "Loss: 2.300241\n",
            "Training epoch 12...\n",
            "Loss: 2.300238\n",
            "Training epoch 13...\n",
            "Loss: 2.300241\n",
            "Training epoch 14...\n",
            "Loss: 2.300239\n",
            "Training epoch 15...\n",
            "Loss: 2.300234\n",
            "Training epoch 16...\n",
            "Loss: 2.300243\n",
            "Training epoch 17...\n",
            "Loss: 2.300239\n",
            "Training epoch 18...\n",
            "Loss: 2.300240\n",
            "Training epoch 19...\n",
            "Loss: 2.300239\n",
            "Training epoch 20...\n",
            "Loss: 2.300239\n",
            "Training epoch 21...\n",
            "Loss: 2.300241\n",
            "Training epoch 22...\n",
            "Loss: 2.300236\n",
            "Training epoch 23...\n",
            "Loss: 2.300238\n",
            "Training epoch 24...\n",
            "Loss: 2.300242\n",
            "Training epoch 25...\n",
            "Loss: 2.300237\n",
            "Training epoch 26...\n",
            "Loss: 2.300240\n",
            "Training epoch 27...\n",
            "Loss: 2.300242\n",
            "Training epoch 28...\n",
            "Loss: 2.300241\n",
            "Training epoch 29...\n",
            "Loss: 2.300241\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(30):\n",
        "  print(f'Training epoch {epoch}...')\n",
        "\n",
        "  running_loss =0.0\n",
        "  for i,data in enumerate(train_loader):\n",
        "   inputs, labels = data\n",
        "   optimizer.zero_grad()\n",
        "   outputs =net(inputs)\n",
        "   loss = loss_function(outputs , labels)\n",
        "   loss.backward()\n",
        "   optimizer.step()\n",
        "   running_loss += loss.item()\n",
        "  print(f'Loss: {running_loss / len(train_loader):4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "bW0ahdNXzuqM"
      },
      "outputs": [],
      "source": [
        "torch.save(net.state_dict(), 'trained_net.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBHfsh7jz79l",
        "outputId": "f623250c-1eec-4a1c-f96b-91fc4eef2f93"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net = NeuralNet()\n",
        "net.load_state_dict(torch.load('trained_net.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNjx1NpE0L3u",
        "outputId": "2c0a890c-e322-4f03-dbec-8fc33d3a192b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy :17.46%\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "net.eval()\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    images , labels=data\n",
        "    outputs =net(images)\n",
        "    _,predicted = torch.max(outputs.data,1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "accuracy = 100 *correct/total\n",
        "print(f'Accuracy :{accuracy}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsV6yBw00_Gz",
        "outputId": "3a19f1f2-d6e4-4f93-b8fc-cf0faa052621"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction: ship\n",
            "Prediction: deer\n"
          ]
        }
      ],
      "source": [
        "new_transform = transforms.Compose([\n",
        "    transforms.Resize((32,32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "])\n",
        "\n",
        "def load_image(image_path):\n",
        "  image = Image.open(image_path)\n",
        "  image = new_transform(image)\n",
        "  image = image.unsqueeze(0)\n",
        "  return image\n",
        "# Replace with actual paths to your images\n",
        "image_paths = ['/content/example1.jpg' , '/content/example2.jpg']\n",
        "images = [load_image(img) for img in image_paths]\n",
        "net.eval()\n",
        "with torch.no_grad():\n",
        "  for i in images:\n",
        "    output = net(i)\n",
        "    _,predicted = torch.max(output.data,1)\n",
        "    print(f'Prediction: {class_names[predicted.item()]}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
